{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jA6jBcLwC580"
   },
   "source": [
    "2. 应用题\n",
    "   - 使用选择SARSA，期望 SARSA，Q 学习中的一种方法求解小车爬山控制策略 MoutainCar-v0\n",
    "   - 随机数种子为学号后四位\n",
    "   - 自行对超参数寻优\n",
    "   - 训练好后，输出完全利用（epsilon=0）时的回合总奖励（total_reward）（评分比重 60%）\n",
    "   - 请说明选择该方法的原因（评分比重30%）\n",
    "   - 将代码和结果整理为ipynb格式（文件名“MTB.ipynb”），需要包含训练过程中每个回合的总奖励变化曲线（评分比重10%）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QPrYUlr7C582"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "\n",
    "np.random.seed(5235) # 学号后四位"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AhqDEMsUC587"
   },
   "source": [
    "### 环境使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "id": "lWyjPiyHC588",
    "outputId": "2bc6a5e0-9ed2-4faa-c9ea-9a0f504c127a"
   },
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "env.seed(5235)\n",
    "print('观测空间 = {}'.format(env.observation_space))\n",
    "print('动作空间 = {}'.format(env.action_space))\n",
    "print('位置范围 = {}'.format((env.unwrapped.min_position, \n",
    "        env.unwrapped.max_position)))\n",
    "print('速度范围 = {}'.format((-env.unwrapped.max_speed,\n",
    "        env.unwrapped.max_speed)))\n",
    "print('目标位置 = {}'.format(env.unwrapped.goal_position))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qwJLWgXlC59B"
   },
   "source": [
    "举例控制策略：一直向右"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "kdoLX6PVC59D",
    "outputId": "282ef83e-c8ff-4dd0-bf07-d47cb198ccf6"
   },
   "outputs": [],
   "source": [
    "positions, velocities = [], []\n",
    "observation = env.reset()\n",
    "while True:\n",
    "    positions.append(observation[0])\n",
    "    velocities.append(observation[1])\n",
    "    next_observation, reward, done, _ = env.step(2)\n",
    "    if done:\n",
    "        break\n",
    "    observation = next_observation\n",
    "\n",
    "if next_observation[0] > 0.5:\n",
    "    print('成功到达')\n",
    "else:\n",
    "    print('失败退出')\n",
    "\n",
    "# 绘制位置和速度图像\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(positions, label='position')\n",
    "ax.plot(velocities, label='velocity')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用SARSA算法求解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TileCoder:\n",
    "    def __init__(self, layers, features):\n",
    "        self.layers = layers\n",
    "        self.features = features\n",
    "        self.codebook = {}\n",
    "    \n",
    "    def get_feature(self, codeword):\n",
    "        if codeword in self.codebook:\n",
    "            return self.codebook[codeword]\n",
    "        count = len(self.codebook)\n",
    "        if count >= self.features: # 冲突处理\n",
    "            return hash(codeword) % self.features\n",
    "        self.codebook[codeword] = count\n",
    "        return count\n",
    "    \n",
    "    def __call__(self, floats=(), ints=()):\n",
    "        dim = len(floats)\n",
    "        scaled_floats = tuple(f * self.layers * self.layers for f in floats)\n",
    "        features = []\n",
    "        for layer in range(self.layers):\n",
    "            codeword = (layer,) + tuple(int((f + (1 + dim * i) * layer) /\n",
    "                    self.layers) for i, f in enumerate(scaled_floats)) + ints\n",
    "            feature = self.get_feature(codeword)\n",
    "            features.append(feature)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SARSAAgent:\n",
    "    def __init__(self, env, layers=8, features=1893, gamma=1.,\n",
    "                learning_rate=0.03, epsilon=0.001):\n",
    "        self.action_n = env.action_space.n # 动作数\n",
    "        self.obs_low = env.observation_space.low\n",
    "        self.obs_scale = env.observation_space.high - \\\n",
    "                env.observation_space.low # 观测空间范围\n",
    "        self.encoder = TileCoder(layers, features) # 砖瓦编码器\n",
    "        self.w = np.zeros(features) # 权重\n",
    "        self.gamma = gamma # 折扣\n",
    "        self.learning_rate = learning_rate # 学习率\n",
    "        self.epsilon = epsilon # 探索\n",
    "        \n",
    "    def encode(self, observation, action): # 编码\n",
    "        states = tuple((observation - self.obs_low) / self.obs_scale)\n",
    "        actions = (action,)\n",
    "        return self.encoder(states, actions)\n",
    "    \n",
    "    def get_q(self, observation, action): # 动作价值\n",
    "        features = self.encode(observation, action)\n",
    "        return self.w[features].sum()\n",
    "    \n",
    "    def decide(self, observation): # 判决\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.randint(self.action_n)\n",
    "        else:\n",
    "            qs = [self.get_q(observation, action) for action in\n",
    "                    range(self.action_n)]\n",
    "            return np.argmax(qs)\n",
    "        \n",
    "    def learn(self, observation, action, reward,\n",
    "            next_observation, done, next_action): # 学习\n",
    "        u = reward + (1. - done) * self.gamma * \\\n",
    "                self.get_q(next_observation, next_action)\n",
    "        td_error = u - self.get_q(observation, action)\n",
    "        features = self.encode(observation, action)\n",
    "        self.w[features] += (self.learning_rate * td_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_sarsa(env, agent, train=False, render=False):\n",
    "    episode_reward = 0\n",
    "    observation = env.reset()\n",
    "    action = agent.decide(observation)\n",
    "    while True:\n",
    "        if render:\n",
    "            env.render()\n",
    "        next_observation, reward, done, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "        next_action = agent.decide(next_observation) # 终止状态时此步无意义\n",
    "        if train:\n",
    "            agent.learn(observation, action, reward, next_observation,\n",
    "                    done, next_action)\n",
    "        if done:\n",
    "            break\n",
    "        observation, action = next_observation, next_action\n",
    "    return episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = SARSAAgent(env)\n",
    "\n",
    "# 训练\n",
    "episodes = 400\n",
    "episode_rewards = []\n",
    "for episode in range(episodes):\n",
    "    episode_reward = play_sarsa(env, agent, train=True)\n",
    "    episode_rewards.append(episode_reward)\n",
    "plt.plot(episode_rewards)\n",
    "\n",
    "# 测试\n",
    "agent.epsilon = 0. # 取消探索\n",
    "episode_rewards = [play_sarsa(env, agent) for _ in range(100)]\n",
    "print('平均回合奖励 = {} / {} = {}'.format(sum(episode_rewards),\n",
    "        len(episode_rewards), np.mean(episode_rewards)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MountainCar_v0_201901302220.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
